{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35996021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e3194f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>timeseries-tas-monthly-mean</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901-01-16</td>\n",
       "      <td>26.25</td>\n",
       "      <td>-122.75</td>\n",
       "      <td>16.322001</td>\n",
       "      <td>1901</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901-01-16</td>\n",
       "      <td>26.25</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>16.322001</td>\n",
       "      <td>1901</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901-01-16</td>\n",
       "      <td>26.25</td>\n",
       "      <td>-121.75</td>\n",
       "      <td>16.322001</td>\n",
       "      <td>1901</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901-01-16</td>\n",
       "      <td>26.25</td>\n",
       "      <td>-121.25</td>\n",
       "      <td>16.322001</td>\n",
       "      <td>1901</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1901-01-16</td>\n",
       "      <td>26.25</td>\n",
       "      <td>-120.75</td>\n",
       "      <td>16.322001</td>\n",
       "      <td>1901</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time    lat     lon  timeseries-tas-monthly-mean  year  month  \\\n",
       "0  1901-01-16  26.25 -122.75                    16.322001  1901      1   \n",
       "1  1901-01-16  26.25 -122.25                    16.322001  1901      1   \n",
       "2  1901-01-16  26.25 -121.75                    16.322001  1901      1   \n",
       "3  1901-01-16  26.25 -121.25                    16.322001  1901      1   \n",
       "4  1901-01-16  26.25 -120.75                    16.322001  1901      1   \n",
       "\n",
       "   dayofyear  quarter  \n",
       "0         16        1  \n",
       "1         16        1  \n",
       "2         16        1  \n",
       "3         16        1  \n",
       "4         16        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Updated_CRU.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68cfa5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6644352, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bbd29dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft = df[['time', 'timeseries-tas-monthly-mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1836ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft['time'] = pd.to_datetime(df_ft['time'])\n",
    "df_ft.set_index('time', inplace=True)\n",
    "df_ft.rename(columns={'timeseries-tas-monthly-mean': 'temperature'}, inplace=True)\n",
    "df_ft = df_ft['temperature'].resample('D').mean()\n",
    "df_ft = df_ft.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ffa2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44165, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dbf00f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901-01-16</td>\n",
       "      <td>2.729315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901-01-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901-01-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901-01-19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1901-01-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  temperature\n",
       "0 1901-01-16     2.729315\n",
       "1 1901-01-17          NaN\n",
       "2 1901-01-18          NaN\n",
       "3 1901-01-19          NaN\n",
       "4 1901-01-20          NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "332b468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft['year'] = df_ft['time'].dt.year\n",
    "df_ft[\"week\"] = df_ft['time'].dt.isocalendar().week\n",
    "df_ft['month'] = df_ft['time'].dt.month\n",
    "df_ft['quarter'] = df_ft['time'].dt.quarter\n",
    "df_ft['dayofyear'] = df_ft['time'].dt.dayofyear\n",
    "df_ft['dayofweek'] = df_ft['time'].dt.dayofweek\n",
    "df_ft[\"is_month_start\"] = df_ft['time'].dt.is_month_start\n",
    "df_ft[\"is_month_end\"] = df_ft['time'].dt.is_month_end\n",
    "df_ft[\"is_quarter_start\"] = df_ft['time'].dt.is_quarter_start\n",
    "df_ft[\"is_quarter_end\"] = df_ft['time'].dt.is_quarter_end\n",
    "df_ft[\"is_year_start\"] = df_ft['time'].dt.is_year_start\n",
    "df_ft[\"is_year_end\"] = df_ft['time'].dt.is_year_end\n",
    "df_ft[\"days_in_month\"] = df_ft['time'].dt.days_in_month\n",
    "df_ft[\"is_leap_year\"] = df_ft['time'].dt.is_leap_year\n",
    "df_ft['is_weekend'] = np.where(df_ft['dayofweek'].isin([5, 6]), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73c688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n",
    "\n",
    "\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi))\n",
    "\n",
    "\n",
    "df_ft[\"sin_week\"] = sin_transformer(7).fit_transform(df_ft['week'])\n",
    "df_ft[\"sin_month\"] = sin_transformer(12).fit_transform(df_ft['month'])\n",
    "df_ft[\"sin_quarter\"] = sin_transformer(4).fit_transform(df_ft['quarter'])\n",
    "df_ft[\"sin_dayofyear\"] = sin_transformer(365).fit_transform(df_ft['dayofyear'])\n",
    "df_ft['sin_day_of_week'] = sin_transformer(7).fit_transform(df_ft['dayofweek'])\n",
    "\n",
    "df_ft[\"cos_week\"] = cos_transformer(7).fit_transform(df_ft['week'])\n",
    "df_ft[\"cos_month\"] = cos_transformer(12).fit_transform(df_ft['month'])\n",
    "df_ft[\"cos_quarter\"] = cos_transformer(4).fit_transform(df_ft['quarter'])\n",
    "df_ft[\"cos_dayofyear\"] = cos_transformer(365).fit_transform(df_ft['dayofyear'])\n",
    "df_ft['cos_day_of_week'] = cos_transformer(7).fit_transform(df_ft['dayofweek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25076a6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model_LSTM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Define the LSTM model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel_LSTM\u001b[49m(num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, hidden_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m, lstm_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Define the loss function and optimizer\u001b[39;00m\n\u001b[0;32m      8\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Model_LSTM' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Model_LSTM(num_features=1, hidden_units=128, timesteps=24, lstm_layers=2)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Prepare the data for training\n",
    "# Assume your data is stored in a variable called 'data'\n",
    "\n",
    "# split the data into training and test sets\n",
    "train_data = df[:5000000, :]\n",
    "test_data = df[5000000:, :]\n",
    "\n",
    "# Extract the temperature values and convert to a tensor\n",
    "temp_train = torch.tensor(train_data[:, 0], dtype=torch.float32)\n",
    "temp_test = torch.tensor(test_data[:, 0], dtype=torch.float32)\n",
    "\n",
    "# Normalize the temperature values\n",
    "temp_mean = temp_train.mean()\n",
    "temp_std = temp_train.std()\n",
    "temp_train = (temp_train - temp_mean) / temp_std\n",
    "temp_test = (temp_test - temp_mean) / temp_std\n",
    "\n",
    "# Reshape the temperature values to 3D tensor with shape (batch_size, timesteps, num_features)\n",
    "# Assume you want to use a batch size of 256 and timesteps of 24\n",
    "batch_size = 256\n",
    "timesteps = 24\n",
    "temp_train = temp_train.reshape(-1, timesteps, 1)\n",
    "temp_test = temp_test.reshape(-1, timesteps, 1)\n",
    "\n",
    "# Define the number of training and test samples\n",
    "num_train_samples = temp_train.shape[0]\n",
    "num_test_samples = temp_test.shape[0]\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Shuffle the training data\n",
    "    perm = torch.randperm(num_train_samples)\n",
    "    temp_train = temp_train[perm]\n",
    "\n",
    "    # Initialize the hidden state\n",
    "    hidden = (torch.randn(lstm_layers, batch_size, hidden_units),\n",
    "              torch.randn(lstm_layers, batch_size, hidden_units))\n",
    "\n",
    "    # Iterate over the training batches\n",
    "    for i in range(0, num_train_samples, batch_size):\n",
    "\n",
    "        # Get the current batch\n",
    "        temp_batch = temp_train[i:i+batch_size]\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(temp_batch)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(output, temp_batch)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the training loss\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluation on test set\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Initialize the hidden state\n",
    "    hidden = (torch.randn(lstm_layers, batch_size, hidden_units),\n",
    "              torch.randn(lstm_layers, batch_size, hidden_units))\n",
    "\n",
    "# Initialize the test loss\n",
    "test_loss = 0\n",
    "\n",
    "# Iterate over the test batches\n",
    "for i in range(0, num_test_samples, batch_size):\n",
    "\n",
    "    # Get the current batch\n",
    "    temp_batch = temp_test[i:i+batch_size]\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(temp_batch)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(output, temp_batch)\n",
    "    test_loss += loss.item()\n",
    "\n",
    "# Print the test loss\n",
    "test_loss /= num_test_samples / batch_size\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63dac073",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series = df_ft.loc[(df_ft['time'] >= '1900-01-16') & (df_ft['time'] < '2010-01-16'), :]\n",
    "test_series = df_ft.loc[(df_ft['time'] >= '2010-01-16'), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14851a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_series.drop(['time', 'temperature'], axis=1)\n",
    "y = train_series['temperature'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8de81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaler = StandardScaler().fit(X_train)\n",
    "target_scaler = StandardScaler().fit(y_train.reshape(-1, 1))\n",
    "\n",
    "X_train = train_scaler.transform(X_train)\n",
    "y_train = target_scaler.transform(y_train.reshape(-1, 1))\n",
    "\n",
    "X_val = train_scaler.transform(X_test)\n",
    "y_val = target_scaler.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afcccf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_2820\\258293069.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_series.drop('time', axis=1, inplace=True)\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_2820\\258293069.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_series.drop('time', axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_series.drop('time', axis=1, inplace=True)\n",
    "test_series.drop('time', axis=1, inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_series)\n",
    "scaled_train = scaler.transform(train_series)\n",
    "scaled_test = scaler.transform(test_series)\n",
    "\n",
    "\n",
    "def df_to_x_y(df, window_size=1):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window_size):\n",
    "        row = [[a] for a in df[i: i + window_size, 0]]\n",
    "        X.append(row)\n",
    "        label = df[i + window_size, 0]\n",
    "        y.append(label)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1e7a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 60\n",
    "X_1, y_1 = df_to_x_y(scaled_train, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92f1e340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39737, 60, 1) (39737,)\n"
     ]
    }
   ],
   "source": [
    "print(X_1.shape, y_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8a5dc28",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "X_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "572ea3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31789.600000000002"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "39737 * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d30664b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_1[:31790], y_1[:31790]\n",
    "X_test, y_test = X_1[31790:], y_1[31790:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e050e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "994/994 [==============================] - 29s 29ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "113/994 [==>...........................] - ETA: 23s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[0;32m      8\u001b[0m     min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m      9\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     10\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, shuffle=False)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001,\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"No. Of Epochs\")\n",
    "plt.ylabel(\"mse score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6081d794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_2820\\531871185.py:1: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  X_train_tensors = Variable(torch.Tensor(X_train))\n"
     ]
    }
   ],
   "source": [
    "X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "X_test_tensors = Variable(torch.Tensor(X_val))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "y_test_tensors = Variable(torch.Tensor(y_val)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c7ee651",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da07c6bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape torch.Size([1046, 1, 25]) torch.Size([1046, 1])\n",
      "Testing Shape torch.Size([262, 1, 25]) torch.Size([262, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Shape\", X_train_tensors_final.shape, y_train_tensors.shape)\n",
    "print(\"Testing Shape\", X_test_tensors_final.shape, y_test_tensors.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60261fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 128) #fully connected 1\n",
    "        self.fc = nn.Linear(128, num_classes) #fully connected last layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = self.relu(out) #relu\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "164e55c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 25\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb90ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = LSTM1(output_size, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a39fab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31b86d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.01582\n",
      "Epoch: 100, loss: 0.39306\n",
      "Epoch: 200, loss: 0.08312\n",
      "Epoch: 300, loss: 0.04919\n",
      "Epoch: 400, loss: 0.03550\n",
      "Epoch: 500, loss: 0.02697\n",
      "Epoch: 600, loss: 0.02303\n",
      "Epoch: 700, loss: 0.02038\n",
      "Epoch: 800, loss: 0.01915\n",
      "Epoch: 900, loss: 0.01857\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm1.forward(X_train_tensors_final) #forward pass\n",
    "    optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    " \n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, y_train_tensors)\n",
    " \n",
    "    loss.backward() #calculates the loss of the loss function\n",
    " \n",
    "    optimizer.step() #improve from loss, i.e backprop\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "059934c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_predict \u001b[38;5;241m=\u001b[39m \u001b[43mlstm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#forward pass\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data_predict \u001b[38;5;241m=\u001b[39m train_predict\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;66;03m#numpy conversion\u001b[39;00m\n\u001b[0;32m      3\u001b[0m dataY_plot \u001b[38;5;241m=\u001b[39m df_y_mm\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36mLSTM1.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 18\u001b[0m     h_0 \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)) \u001b[38;5;66;03m#hidden state\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     c_0 \u001b[38;5;241m=\u001b[39m Variable(torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)) \u001b[38;5;66;03m#internal state\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Propagate input through LSTM\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "train_predict = lstm1(X_train)#forward pass\n",
    "data_predict = train_predict.data.numpy() #numpy conversion\n",
    "dataY_plot = df_y_mm.data.numpy()\n",
    "\n",
    "data_predict = mm.inverse_transform(data_predict) #reverse transformation\n",
    "dataY_plot = mm.inverse_transform(dataY_plot)\n",
    "plt.figure(figsize=(10,6)) #plotting\n",
    "plt.axvline(x=200, c='r', linestyle='--') #size of the training set\n",
    "\n",
    "plt.plot(dataY_plot, label='Actuall Data') #actual plot\n",
    "plt.plot(data_predict, label='Predicted Data') #predicted plot\n",
    "plt.title('Time-Series Prediction')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6790afc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_LSTM(nn.Module):\n",
    "    def __init__(self, num_features, hidden_units, timesteps, lstm_layers=1):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.num_features = num_features  # this is the number of features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = lstm_layers\n",
    "        self.seq_len = timesteps\n",
    "        # self.proj_size = 64\n",
    "        dense1 = 1024\n",
    "        dense2 = 512\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_features,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout = 0.2,\n",
    "            # proj_size = self.proj_size\n",
    "        )\n",
    "        # self.lstm_linear = nn.Linear(in_features=self.hidden_units*self.num_layers, out_features=1024)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.lstm_linear = nn.Linear(self.seq_len*self.hidden_units,dense1)\n",
    "        self.linear_mid = nn.Linear(dense1,dense2)\n",
    "        self.linear_out = nn.Linear(dense2,1)\n",
    "    def forward(self, x):\n",
    "        \n",
    "        lstm_out, (hn, _) = self.lstm(x)\n",
    "        \n",
    "        ## all lstm layer hidden states\n",
    "        lstm_out = lstm_out.reshape(lstm_out.shape[0], -1)\n",
    "        out0 = self.lstm_linear(lstm_out)\n",
    "        out0 = self.dropout(out0)\n",
    "        \n",
    "        out1 = self.linear_mid(out0)\n",
    "        out1 = self.dropout(out1)\n",
    "        out = self.linear_out(out1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3f9a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79f4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6858d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c4af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2153a50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95750ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
